{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of FL_working.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbv/yKK+J5o0+0DY49iRjs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasusundaraj/Academic_repo/blob/master/Copy_of_FL_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afUqjDYxBcCc",
        "outputId": "2a4d37b2-289d-48fb-d2d7-241755ce293b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-privacy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (0.1.6)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.2.1)\n",
            "Requirement already satisfied: tensorflow-estimator>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (2.5.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.4.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from dm-tree~=0.1.1->tensorflow-privacy) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.17->tensorflow-privacy) (1.19.5)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.7/dist-packages (1.5.4)\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet --upgrade tensorflow_federated\n",
        "!pip install tensorflow-privacy\n",
        "!pip install nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "import sys\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    import warnings\n",
        "    warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import tensorflow_privacy\n",
        "import collections\n",
        "import attr\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "\n",
        "from absl import app\n",
        "from absl import flags\n",
        "import numpy as np\n",
        "from scipy import io\n",
        "from tensorflow_federated.python.tensorflow_libs import tensor_utils\n",
        "from tensorflow_federated.python.core.api import computations\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0MGlVEYPB6io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_clients = 3"
      ],
      "metadata": {
        "id": "P2yjFNC6CCAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEEI0z5sDuah"
      },
      "source": [
        "@attr.s(eq=False, frozen=True)\n",
        "class ClientOutput(object):\n",
        "  \"\"\"Structure for outputs returned from clients during federated optimization.\n",
        "  Fields:\n",
        "  -   `weights_delta`: A dictionary of updates to the model's trainable\n",
        "      variables.\n",
        "  -   `weights_delta_weight`: Weight to be used in a weighted mean when\n",
        "      aggregating `weights_delta`.\n",
        "  -   `model_output`: A structure matching\n",
        "      `tff.learning.Model.report_local_outputs`, reflecting the results of\n",
        "      training on the input dataset.\n",
        "  -   `optimizer_output`: Additional metrics or other outputs defined by the\n",
        "      optimizer.\n",
        "  \"\"\"\n",
        "  weights_delta = attr.ib()\n",
        "  weights_delta_weight = attr.ib()\n",
        "  model_output = attr.ib()\n",
        "  response_time = attr.ib()\n",
        "  optimizer_output = attr.ib()\n",
        "\n",
        "\n",
        "@attr.s(eq=False, frozen=True)\n",
        "class ServerState(object):\n",
        "  \"\"\"Structure for state on the server.\n",
        "  Fields:\n",
        "  -   `model`: A dictionary of model's trainable variables.\n",
        "  -   `optimizer_state`: Variables of optimizer.\n",
        "  \"\"\"\n",
        "  model = attr.ib()\n",
        "  optimizer_state = attr.ib()\n",
        "  delta_aggregate_state = attr.ib()\n",
        "\n",
        "\n",
        "def _create_optimizer_vars(model, optimizer):\n",
        "  model_weights = _get_weights(model)\n",
        "  delta = tf.nest.map_structure(tf.zeros_like, model_weights.trainable)\n",
        "  grads_and_vars = tf.nest.map_structure(\n",
        "      lambda x, v: (-1.0 * x, v), tf.nest.flatten(delta),\n",
        "      tf.nest.flatten(model_weights.trainable))\n",
        "  optimizer.apply_gradients(grads_and_vars, name='server_update')\n",
        "  return optimizer.variables()\n",
        "\n",
        "\n",
        "def _get_weights(model):\n",
        "  return tff.learning.framework.ModelWeights.from_model(model)\n",
        "\n",
        "\n",
        "def _get_norm(weights):\n",
        "  \"\"\"Compute the norm of a weight matrix.\n",
        "  Args:\n",
        "    weights: a OrderedDict specifying weight matrices at different layers.\n",
        "  Returns:\n",
        "    The norm of all layer weight matrices.\n",
        "  \"\"\"\n",
        "  return tf.linalg.global_norm(tf.nest.flatten(weights))\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def server_update(model, server_optimizer, server_optimizer_vars, server_state,\n",
        "                  weights_delta, new_delta_aggregate_state):\n",
        "  \"\"\"Updates `server_state` based on `weights_delta`.\n",
        "  Args:\n",
        "    model: A `tff.learning.Model`.\n",
        "    server_optimizer: A `tf.keras.optimizers.Optimizer`.\n",
        "    server_optimizer_vars: A list of previous variables of server_optimzer.\n",
        "    server_state: A `ServerState`, the state to be updated.\n",
        "    weights_delta: An update to the trainable variables of the model.\n",
        "    new_delta_aggregate_state: An update to the server state.\n",
        "  Returns:\n",
        "    An updated `ServerState`.\n",
        "  \"\"\"\n",
        "  model_weights = _get_weights(model)\n",
        "  tf.nest.map_structure(lambda a, b: a.assign(b),\n",
        "                        (model_weights, server_optimizer_vars),\n",
        "                        (server_state.model, server_state.optimizer_state))\n",
        "\n",
        "  grads_and_vars = tf.nest.map_structure(\n",
        "      lambda x, v: (-1.0 * x, v), tf.nest.flatten(weights_delta),\n",
        "      tf.nest.flatten(model_weights.trainable))\n",
        "  server_optimizer.apply_gradients(grads_and_vars, name='server_update')\n",
        "\n",
        "  return tff.structure.update_struct(\n",
        "      server_state,\n",
        "      model=model_weights,\n",
        "      optimizer_state=server_optimizer_vars,\n",
        "      delta_aggregate_state=new_delta_aggregate_state)\n",
        "\n",
        "\n",
        "\n",
        "def build_server_init_fn(model_fn, server_optimizer_fn,\n",
        "                         aggregation_process_init):\n",
        "  \"\"\"Builds a `tff.Computation` that returns initial `ServerState`.\n",
        "  Args:\n",
        "    model_fn: A no-arg function that returns a `tff.learning.Model`.\n",
        "    server_optimizer_fn: A no-arg function that returns a\n",
        "      `tf.keras.optimizers.Optimizer`.\n",
        "    aggregation_process_init: A `tff.Computation` that initializes the\n",
        "      aggregator state.\n",
        "  Returns:\n",
        "    A `tff.tf_computation` that returns initial `ServerState`.\n",
        "  \"\"\"\n",
        "\n",
        "  @tff.tf_computation\n",
        "  def server_init_tf():\n",
        "    model = model_fn()\n",
        "    server_optimizer = server_optimizer_fn()\n",
        "    # Create optimizer variables so we have a place to assign the optimizer's\n",
        "    # state.\n",
        "    server_optimizer_vars = _create_optimizer_vars(model, server_optimizer)\n",
        "    return _get_weights(model), server_optimizer_vars\n",
        "\n",
        "  @tff.federated_computation\n",
        "  def server_init():\n",
        "    initial_model, server_optimizer_state = tff.federated_eval(\n",
        "        server_init_tf, tff.SERVER)\n",
        "    return tff.federated_zip(\n",
        "        ServerState(\n",
        "            model=initial_model,\n",
        "            optimizer_state=server_optimizer_state,\n",
        "            delta_aggregate_state=aggregation_process_init()))\n",
        "\n",
        "  return server_init\n",
        "\n",
        "\n",
        "def build_server_update_fn(model_fn, server_optimizer_fn, server_state_type,\n",
        "                           model_weights_type):\n",
        "  \"\"\"Builds a `tff.tf_computation` that updates `ServerState`.\n",
        "  Args:\n",
        "    model_fn: A no-arg function that returns a `tff.learning.Model`.\n",
        "    server_optimizer_fn: A no-arg function that returns a\n",
        "      `tf.keras.optimizers.Optimizer`.\n",
        "    server_state_type: type_signature of server state.\n",
        "    model_weights_type: type_signature of model weights.\n",
        "  Returns:\n",
        "    A `tff.tf_computation` that updates `ServerState`.\n",
        "  \"\"\"\n",
        "\n",
        "  @tff.tf_computation(server_state_type, model_weights_type.trainable,\n",
        "                      server_state_type.delta_aggregate_state)\n",
        "  def server_update_tf(server_state, model_delta, new_delta_aggregate_state):\n",
        "    \"\"\"Updates the `server_state`.\n",
        "    Args:\n",
        "      server_state: The `ServerState`.\n",
        "      model_delta: The model difference from clients.\n",
        "      new_delta_aggregate_state: An update to the server state.\n",
        "    Returns:\n",
        "      The updated `ServerState`.\n",
        "    \"\"\"\n",
        "    model = model_fn()\n",
        "    server_optimizer = server_optimizer_fn()\n",
        "    # Create optimizer variables so we have a place to assign the optimizer's\n",
        "    # state.\n",
        "    server_optimizer_vars = _create_optimizer_vars(model, server_optimizer)\n",
        "\n",
        "    return server_update(model, server_optimizer, server_optimizer_vars,\n",
        "                         server_state, model_delta, new_delta_aggregate_state)\n",
        "\n",
        "  return server_update_tf\n",
        "\n",
        "\n",
        "def build_client_update_fn(model_fn, optimizer_fn, client_update_tf,\n",
        "                           tf_dataset_type, model_weights_type):\n",
        "  \"\"\"Builds a `tff.tf_computation` in the presense of malicious clients.\n",
        "  Args:\n",
        "    model_fn: A no-arg function that returns a `tff.learning.Model`.\n",
        "    optimizer_fn: A no-arg function that returns a\n",
        "      `tf.keras.optimizers.Optimizer`.\n",
        "    client_update_tf: A 'tf.function' that computes the ClientOutput\n",
        "    tf_dataset_type: type_signature of dataset.\n",
        "    model_weights_type: type_signature of model weights.\n",
        "  Returns:\n",
        "    A `tff.tf_computation` for local model optimization with type signature:\n",
        "    '@tff.tf_computation(tf_dataset_type, tf_dataset_type,\n",
        "                      tf.bool, model_weights_type)'\n",
        "  \"\"\"\n",
        "\n",
        "  @tff.tf_computation(tf_dataset_type, tf_dataset_type, tf.bool,\n",
        "                      model_weights_type)\n",
        "  def client_delta_tf(benign_dataset, malicious_dataset, client_type,\n",
        "                      initial_model_weights):\n",
        "    \"\"\"Performs client local model optimization.\n",
        "    Args:\n",
        "      benign_dataset: A 'tf.data.Dataset' consisting of benign dataset\n",
        "      malicious_dataset: A 'tf.data.Dataset' consisting of malicious dataset\n",
        "      client_type: A 'tf.bool' indicating whether the client is malicious\n",
        "      initial_model_weights: A `tff.learning.Model.weights` from server.\n",
        "    Returns:\n",
        "      A 'ClientOutput`.\n",
        "    \"\"\"\n",
        "    # Create variables here in the graph context, before calling the tf.function\n",
        "    # below.\n",
        "    model = model_fn()\n",
        "    optimizer = optimizer_fn()\n",
        "    return client_update_tf(model, optimizer, benign_dataset, malicious_dataset,\n",
        "                            client_type, initial_model_weights)\n",
        "\n",
        "  return client_delta_tf\n",
        "\n",
        "class ClientExplicitBoosting:\n",
        "  \"\"\"Client tensorflow logic for explicit boosting.\"\"\"\n",
        "\n",
        "  def __init__(self, boost_factor):\n",
        "    \"\"\"Specify the boosting parameter.\n",
        "    Args:\n",
        "      boost_factor: A 'tf.float32' specifying how malicious update is boosted.\n",
        "    \"\"\"\n",
        "    self.boost_factor = boost_factor\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, model, optimizer, benign_dataset, malicious_dataset,\n",
        "               client_type, initial_weights):\n",
        "    \"\"\"Updates client model with client potentially being malicious.\n",
        "    Args:\n",
        "      model: A `tff.learning.Model`.\n",
        "      optimizer: A 'tf.keras.optimizers.Optimizer'.\n",
        "      benign_dataset: A 'tf.data.Dataset' consisting of benign dataset.\n",
        "      malicious_dataset: A 'tf.data.Dataset' consisting of malicious dataset.\n",
        "      client_type: A 'tf.bool' indicating whether the client is malicious; iff\n",
        "        `True` the client will construct its update using `malicious_dataset`,\n",
        "        otherwise will construct the update using `benign_dataset`.\n",
        "      initial_weights: A `tff.learning.Model.weights` from server.\n",
        "    Returns:\n",
        "      A 'ClientOutput`.\n",
        "    \"\"\"\n",
        "    model_weights = _get_weights(model)\n",
        "\n",
        "    @tf.function\n",
        "    def reduce_fn(num_examples_sum, batch):\n",
        "      \"\"\"Runs `tff.learning.Model.train_on_batch` on local client batch.\"\"\"\n",
        "      with tf.GradientTape() as tape:\n",
        "        output = model.forward_pass(batch)\n",
        "      gradients = tape.gradient(output.loss, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "      return num_examples_sum + tf.shape(output.predictions)[0]\n",
        "\n",
        "    @tf.function\n",
        "    def compute_benign_update():\n",
        "      \"\"\"compute benign update sent back to the server.\"\"\"\n",
        "      tf.nest.map_structure(lambda a, b: a.assign(b), model_weights,\n",
        "                            initial_weights)\n",
        "\n",
        "      num_examples_sum = benign_dataset.reduce(\n",
        "          initial_state=tf.constant(0), reduce_func=reduce_fn)\n",
        "\n",
        "      weights_delta_benign = tf.nest.map_structure(lambda a, b: a - b,\n",
        "                                                   model_weights.trainable,\n",
        "                                                   initial_weights.trainable)\n",
        "\n",
        "      aggregated_outputs = model.report_local_outputs()\n",
        "\n",
        "      return weights_delta_benign, aggregated_outputs, num_examples_sum\n",
        "\n",
        "    @tf.function\n",
        "    def compute_malicious_update():\n",
        "      \"\"\"compute malicious update sent back to the server.\"\"\"\n",
        "      result = compute_benign_update()\n",
        "      weights_delta_benign, aggregated_outputs, num_examples_sum = result\n",
        "\n",
        "      tf.nest.map_structure(lambda a, b: a.assign(b), model_weights,\n",
        "                            initial_weights)\n",
        "\n",
        "      malicious_dataset.reduce(\n",
        "          initial_state=tf.constant(0), reduce_func=reduce_fn)\n",
        "\n",
        "      weights_delta_malicious = tf.nest.map_structure(lambda a, b: a - b,\n",
        "                                                      model_weights.trainable,\n",
        "                                                      initial_weights.trainable)\n",
        "\n",
        "      weights_delta = tf.nest.map_structure(\n",
        "          tf.add, weights_delta_benign,\n",
        "          tf.nest.map_structure(lambda delta: delta * self.boost_factor,\n",
        "                                weights_delta_malicious))\n",
        "\n",
        "      return weights_delta, aggregated_outputs, num_examples_sum\n",
        "    \n",
        "    result = tf.cond(\n",
        "        tf.equal(client_type, True), compute_malicious_update,\n",
        "        compute_benign_update)\n",
        "    weights_delta, aggregated_outputs, num_examples_sum = result\n",
        "\n",
        "    weights_delta_weight = tf.cast(num_examples_sum, tf.float32)\n",
        "    response_time = 0\n",
        "    weight_norm = _get_norm(weights_delta)\n",
        "\n",
        "    return ClientOutput(\n",
        "        weights_delta, weights_delta_weight, aggregated_outputs, response_time,\n",
        "        collections.OrderedDict({\n",
        "            'num_examples': num_examples_sum,\n",
        "            'weight_norm': weight_norm,\n",
        "        }))\n",
        "\n",
        "\n",
        "def build_run_one_round_fn_attacked(server_update_fn, client_update_fn,\n",
        "                                    aggregation_process,\n",
        "                                    dummy_model_for_metadata,\n",
        "                                    federated_server_state_type,\n",
        "                                    federated_dataset_type,benign_clientoutput_list,counter):\n",
        "  \"\"\"Builds a `tff.federated_computation` for a round of training.\n",
        "  Args:\n",
        "    server_update_fn: A function for updates in the server.\n",
        "    client_update_fn: A function for updates in the clients.\n",
        "    aggregation_process: A 'tff.templates.AggregationProcess' that takes in\n",
        "      model deltas placed@CLIENTS to an aggregated model delta placed@SERVER.\n",
        "    dummy_model_for_metadata: A dummy `tff.learning.Model`.\n",
        "    federated_server_state_type: type_signature of federated server state.\n",
        "    federated_dataset_type: type_signature of federated dataset.\n",
        "  Returns:\n",
        "    A `tff.federated_computation` for a round of training.\n",
        "  \"\"\"\n",
        "  @tff.tf_computation\n",
        "  def cast_to_float(x):\n",
        "    return tf.cast(x, tf.float32)\n",
        " \n",
        "  federated_bool_type = tff.type_at_clients(tf.bool)\n",
        "\n",
        "  @tff.federated_computation(federated_server_state_type,\n",
        "                             federated_dataset_type, federated_dataset_type,\n",
        "                             federated_bool_type)\n",
        "  def run_one_round(server_state, federated_dataset, malicious_dataset,\n",
        "                    malicious_clients):\n",
        "    \"\"\"Orchestration logic for one round of computation.\n",
        "    Args:\n",
        "      server_state: A `ServerState`.\n",
        "      federated_dataset: A federated `tf.Dataset` with placement `tff.CLIENTS`.\n",
        "      malicious_dataset: A federated `tf.Dataset` with placement `tff.CLIENTS`.\n",
        "        consisting of malicious datasets.\n",
        "      malicious_clients: A federated `tf.bool` with placement `tff.CLIENTS`.\n",
        "    Returns:\n",
        "      A tuple of updated `ServerState` and the result of\n",
        "      `tff.learning.Model.federated_output_computation`.\n",
        "    \"\"\"\n",
        "    \n",
        "       \n",
        "\n",
        "    client_model = tff.federated_broadcast(server_state.model)#server weights(1st round its a initial weight)\n",
        "    \n",
        "    client_outputs = tff.federated_map(\n",
        "        client_update_fn,\n",
        "        (federated_dataset, malicious_dataset, malicious_clients, client_model))\n",
        "    # client_type = tff.federated_map(tff.tf_computation(lambda x: True if a > 0.4 else False,client_outputs.response_time)))\n",
        "    #threshold = tff.federated_mean(client_outputs.response_time)\n",
        "    #virtual_outputs = tff.federated_map(\n",
        "        #client_update_fn,\n",
        "        #(federated_dataset, malicious_dataset, virtual_clients, client_model))\n",
        "    \n",
        "    #new_client_outputs = tff.federated_map(tff.tf_computation(tf.nest.map_structure(lambda a, b: a.assign(b), client_outputs,virtual_outputs)))\n",
        "    \n",
        "    \n",
        "    weight_denom = client_outputs.weights_delta_weight\n",
        "    \n",
        "    if aggregation_process.is_weighted:\n",
        "      aggregate_output = aggregation_process.next(\n",
        "          server_state.delta_aggregate_state,\n",
        "          client_outputs.weights_delta,\n",
        "          weight=weight_denom)\n",
        "    else:\n",
        "      aggregate_output = aggregation_process.next(\n",
        "          server_state.delta_aggregate_state, client_outputs.weights_delta)\n",
        "    new_delta_aggregate_state = aggregate_output.state\n",
        "    round_model_delta = aggregate_output.result\n",
        "\n",
        "    server_state = tff.federated_map(\n",
        "        server_update_fn,\n",
        "        (server_state, round_model_delta, new_delta_aggregate_state))\n",
        "\n",
        "    aggregated_outputs = dummy_model_for_metadata.federated_output_computation(\n",
        "        client_outputs.model_output)\n",
        "    if isinstance(aggregated_outputs.type_signature, tff.StructType):\n",
        "      aggregated_outputs = tff.federated_zip(aggregated_outputs)\n",
        "\n",
        "    return server_state, aggregated_outputs,client_outputs.weights_delta\n",
        "    \n",
        "  return run_one_round\n",
        "\n",
        "\n",
        "def build_federated_averaging_process_attacked(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.1),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),\n",
        "    model_update_aggregation_factory=None,\n",
        "    client_update_tf=ClientExplicitBoosting(boost_factor=1.0)):\n",
        "  \"\"\"Builds the TFF computations for optimization using federated averaging with potentially malicious clients.\n",
        "  Args:\n",
        "    model_fn: A no-arg function that returns a `tff.learning.Model`.\n",
        "    client_optimizer_fn: A no-arg function that returns a\n",
        "      `tf.keras.optimizers.Optimizer`, use during local client training.\n",
        "    server_optimizer_fn: A no-arg function that returns a\n",
        "      `tf.keras.optimizers.Optimizer`, use to apply updates to the global model.\n",
        "    model_update_aggregation_factory: An optional\n",
        "      `tff.aggregators.AggregationFactory` that contstructs\n",
        "      `tff.templates.AggregationProcess` for aggregating the client model\n",
        "      updates on the server. If `None`, uses a default constructed\n",
        "      `tff.aggregators.MeanFactory`, creating a stateless mean aggregation.\n",
        "    client_update_tf: a 'tf.function' computes the ClientOutput.\n",
        "  Returns:\n",
        "    A `tff.templates.IterativeProcess`.\n",
        "  \"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    dummy_model_for_metadata = model_fn()\n",
        "    weights_type = tff.learning.framework.weights_type_from_model(\n",
        "        dummy_model_for_metadata)#returns -created TFF type\n",
        "  \n",
        "  if model_update_aggregation_factory is None:\n",
        "    model_update_aggregation_factory = tff.aggregators.MeanFactory()\n",
        "\n",
        "  if isinstance(model_update_aggregation_factory,\n",
        "                tff.aggregators.WeightedAggregationFactory):\n",
        "    aggregation_process = model_update_aggregation_factory.create(\n",
        "        weights_type.trainable, tff.TensorType(tf.float32))\n",
        "  else:\n",
        "    aggregation_process = model_update_aggregation_factory.create(\n",
        "        weights_type.trainable)\n",
        "\n",
        "  server_init = build_server_init_fn(model_fn, server_optimizer_fn,\n",
        "                                     aggregation_process.initialize)\n",
        "  server_state_type = server_init.type_signature.result.member\n",
        "  server_update_fn = build_server_update_fn(model_fn, server_optimizer_fn,\n",
        "                                            server_state_type,\n",
        "                                            server_state_type.model)\n",
        "  tf_dataset_type = tff.SequenceType(dummy_model_for_metadata.input_spec)\n",
        "\n",
        "  client_update_fn = build_client_update_fn(model_fn, client_optimizer_fn,\n",
        "                                            client_update_tf, tf_dataset_type,\n",
        "                                            server_state_type.model)\n",
        "\n",
        "  federated_server_state_type = tff.type_at_server(server_state_type)\n",
        "\n",
        "  federated_dataset_type = tff.type_at_clients(tf_dataset_type)\n",
        "  benign_clientoutput_list = []\n",
        "  counter = 0\n",
        "  \n",
        "  run_one_round_tff = build_run_one_round_fn_attacked(\n",
        "      server_update_fn, client_update_fn, aggregation_process,\n",
        "      dummy_model_for_metadata, federated_server_state_type,\n",
        "      federated_dataset_type, benign_clientoutput_list,counter)\n",
        "  \n",
        "  \n",
        "  return tff.templates.IterativeProcess(\n",
        "      initialize_fn=server_init, next_fn=run_one_round_tff)\n",
        "\n",
        "\n",
        "class ClientProjectBoost:\n",
        "  \"\"\"Client tensorflow logic for norm bounded attack.\"\"\"\n",
        "\n",
        "  def __init__(self, boost_factor, norm_bound, round_num):\n",
        "    \"\"\"Specify the attacking parameter.\n",
        "    Args:\n",
        "      boost_factor: A 'tf.float32' specifying how malicious update is boosted.\n",
        "      norm_bound: A 'tf.float32' specifying the norm bound before boosting.\n",
        "      round_num: A 'tf.int32' specifying the number of iterative rounds.\n",
        "    \"\"\"\n",
        "    self.boost_factor = boost_factor\n",
        "    self.norm_bound = norm_bound\n",
        "    self.round_num = round_num\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, model, optimizer, benign_dataset, malicious_dataset,\n",
        "               client_is_malicious, initial_weights):\n",
        "    \"\"\"Updates client model with client potentially being malicious.\n",
        "    Args:\n",
        "      model: A `tff.learning.Model`.\n",
        "      optimizer: A 'tf.keras.optimizers.Optimizer'.\n",
        "      benign_dataset: A 'tf.data.Dataset' consisting of benign dataset.\n",
        "      malicious_dataset: A 'tf.data.Dataset' consisting of malicious dataset.\n",
        "      client_is_malicious: A 'tf.bool' showing whether the client is malicious.\n",
        "      initial_weights: A `tff.learning.Model.weights` from server.\n",
        "    Returns:\n",
        "      A 'ClientOutput`.\n",
        "    \"\"\"\n",
        "    model_weights = _get_weights(model)\n",
        "\n",
        "    @tf.function\n",
        "    def clip_by_norm(gradient, norm):\n",
        "      \"\"\"Clip the gradient by its l2 norm.\"\"\"\n",
        "      norm = tf.cast(norm, tf.float32)\n",
        "      delta_norm = _get_norm(gradient)\n",
        "\n",
        "      if delta_norm < norm:\n",
        "        return gradient\n",
        "      else:\n",
        "        delta_mul_factor = tf.math.divide_no_nan(norm, delta_norm)# how much times it larger \n",
        "        return tf.nest.map_structure(lambda g: g * delta_mul_factor, gradient)\n",
        "\n",
        "    @tf.function\n",
        "    def project_weights(weights, initial_weights, norm):\n",
        "      \"\"\"Project the weight onto l2 ball around initial_weights with radius norm.\"\"\"\n",
        "      weights_delta = tf.nest.map_structure(lambda a, b: a - b, weights,\n",
        "                                            initial_weights)\n",
        "\n",
        "      return tf.nest.map_structure(tf.add, clip_by_norm(weights_delta, norm),\n",
        "                                   initial_weights)\n",
        "\n",
        "    @tf.function\n",
        "    def reduce_fn(num_examples_sum, batch):\n",
        "      \"\"\"Runs `tff.learning.Model.train_on_batch` on local client batch.\"\"\"\n",
        "      with tf.GradientTape() as tape:\n",
        "        output = model.forward_pass(batch)\n",
        "      gradients = tape.gradient(output.loss, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "      return num_examples_sum + tf.shape(output.predictions)[0]\n",
        "\n",
        "    @tf.function\n",
        "    def compute_benign_update():\n",
        "      \"\"\"compute benign update sent back to the server.\"\"\"\n",
        "      tf.nest.map_structure(lambda a, b: a.assign(b), model_weights,\n",
        "                            initial_weights)\n",
        "\n",
        "      num_examples_sum = benign_dataset.reduce(\n",
        "          initial_state=tf.constant(0), reduce_func=reduce_fn)\n",
        "      #A dataset element corresponding to the final state of the transformation.\n",
        "\n",
        "      weights_delta_benign = tf.nest.map_structure(lambda a, b: a - b,\n",
        "                                                   model_weights.trainable,\n",
        "                                                   initial_weights.trainable)\n",
        "      #weight_delta eg: model_weight =74, intial weight =70, ans is 4\n",
        "      #np.savetxt()\n",
        "      aggregated_outputs = model.report_local_outputs()#aggregation across clients\n",
        "\n",
        "      return weights_delta_benign, aggregated_outputs, num_examples_sum\n",
        "   \n",
        "    @tf.function\n",
        "    def compute_malicious_update():\n",
        "      \"\"\"compute malicious update sent back to the server.\"\"\"\n",
        "\n",
        "      _, aggregated_outputs, num_examples_sum = compute_benign_update()\n",
        "\n",
        "      tf.nest.map_structure(lambda a, b: a.assign(b), model_weights,\n",
        "                            initial_weights)\n",
        "\n",
        "      for _ in range(self.round_num):\n",
        "        benign_dataset.reduce(\n",
        "            initial_state=tf.constant(0), reduce_func=reduce_fn)\n",
        "        malicious_dataset.reduce(\n",
        "            initial_state=tf.constant(0), reduce_func=reduce_fn)\n",
        "\n",
        "        tf.nest.map_structure(\n",
        "            lambda a, b: a.assign(b), model_weights.trainable,\n",
        "            project_weights(model_weights.trainable, initial_weights.trainable,\n",
        "                            tf.cast(self.norm_bound, tf.float32)))\n",
        "\n",
        "      weights_delta_malicious = tf.nest.map_structure(lambda a, b: a - b,\n",
        "                                                      model_weights.trainable,\n",
        "                                                      initial_weights.trainable)\n",
        "      \n",
        "      weights_delta = tf.nest.map_structure(\n",
        "          lambda update: self.boost_factor * update, weights_delta_malicious)\n",
        "     \n",
        "      return weights_delta, aggregated_outputs, num_examples_sum\n",
        "    \n",
        "    @tf.function\n",
        "    def compute_virtual_update():\n",
        "      tf.nest.map_structure(lambda a, b: a.assign(b), model_weights,\n",
        "                            initial_weights)\n",
        "\n",
        "      num_examples_sum = benign_dataset.reduce(\n",
        "          initial_state=tf.constant(0), reduce_func=reduce_fn)\n",
        "\n",
        "      weights_delta_benign = tf.nest.map_structure(lambda a, b: a - b,\n",
        "                                                   model_weights.trainable,\n",
        "                                                   initial_weights.trainable)\n",
        "      \n",
        "      aggregated_outputs = model.report_local_outputs()\n",
        "    \n",
        "      return weights_delta_benign, aggregated_outputs, num_examples_sum\n",
        "\n",
        "\n",
        "    if client_is_malicious:\n",
        "      malicious_start = time.perf_counter()\n",
        "      result = compute_malicious_update()\n",
        "      malicious_stop = time.perf_counter()\n",
        "      elapsed_time = malicious_stop-malicious_start\n",
        "      #tf.print(\"malicious_elapsed-time\",elapsed_time)\n",
        "      #tf.print(\"weights_ delta of malicious  \",weights_delta)\n",
        "      #tf.print(\"aggregated_outputs of malicious  \",aggregated_outputs)\n",
        "      #tf.print(\"num_examples_sum of malicious  \",num_examples_sum)\n",
        "      \n",
        "    \n",
        "    else:\n",
        "      benign_start = time.perf_counter()\n",
        "      result = compute_benign_update()\n",
        "      benign_stop = time.perf_counter()\n",
        "      elapsed_time = benign_stop-benign_start\n",
        "      #tf.print(\"benign_elapsed-time\",elapsed_time)\n",
        "      #tf.print(\"weights_ delta of benign \",weights_delta)\n",
        "      #tf.print(\"aggregated_outputs of benign \",aggregated_outputs)\n",
        "      \n",
        "      #tf.print(\"benign\",result)\n",
        "\n",
        "    #if elapsed_time > 0.4:\n",
        "      #result = compute_virtual_update()\n",
        "    \n",
        "\n",
        "    \n",
        "    weights_delta, aggregated_outputs, num_examples_sum = result\n",
        "    response_time = elapsed_time\n",
        "    weights_delta_weight = tf.cast(num_examples_sum, tf.float32)\n",
        "    #tf.print(weights_delta)\n",
        "    weight_norm = _get_norm(weights_delta)\n",
        "    #tf.print(\"num_examples_sum of benign\",num_examples_sum)\n",
        "    return  ClientOutput(\n",
        "        weights_delta, weights_delta_weight, aggregated_outputs, response_time,\n",
        "        collections.OrderedDict({\n",
        "            'num_examples': num_examples_sum,\n",
        "            'weight_norm': weight_norm,\n",
        "        }))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc2EscI3DyUn"
      },
      "source": [
        "use_nchw_format = False\n",
        "data_format = 'channels_first' if use_nchw_format else 'channels_last'\n",
        "data_shape = [1, 28, 28] if use_nchw_format else [28, 28, 1]\n",
        "def preprocess(dataset):\n",
        "  \"\"\"Preprocess dataset.\"\"\"\n",
        "\n",
        "  def element_fn(element):\n",
        "    return collections.OrderedDict([\n",
        "        ('x', tf.reshape(element['pixels'], data_shape)),\n",
        "        ('y', tf.reshape(element['label'], [-1])),\n",
        "    ])\n",
        "\n",
        "  return dataset.repeat(5).map(element_fn).batch(20)\n",
        "\n",
        "\n",
        "def load_malicious_dataset(num_tasks):\n",
        "  \"\"\"Load malicious dataset consisting of malicious target samples.\"\"\"\n",
        "  url_malicious_dataset = 'https://storage.googleapis.com/tff-experiments-public/targeted_attack/emnist_malicious/emnist_target.mat'\n",
        "  filename = 'emnist_target.mat'\n",
        "  path = tf.keras.utils.get_file(filename, url_malicious_dataset)\n",
        "  emnist_target_data = io.loadmat(path)\n",
        "  emnist_target_x = emnist_target_data['target_train_x'][0]\n",
        "  emnist_target_y = emnist_target_data['target_train_y'][0]\n",
        "  target_x = np.concatenate(emnist_target_x[-num_tasks:], axis=0)\n",
        "  target_y = np.concatenate(emnist_target_y[-num_tasks:], axis=0)\n",
        "  #print(len(target_x))\n",
        "  dict_malicious = collections.OrderedDict([('x', target_x), ('y', target_y)])\n",
        "  dataset_malicious = tf.data.Dataset.from_tensors(dict_malicious)\n",
        "  return dataset_malicious, target_x, target_y\n",
        "\n",
        "\n",
        "def load_test_data():\n",
        "  \"\"\"Load test data for faster evaluation.\"\"\"\n",
        "  url_test_data = 'https://storage.googleapis.com/tff-experiments-public/targeted_attack/emnist_test_data/emnist_test_data.mat'\n",
        "  filename = 'emnist_test_data.mat'\n",
        "  path = tf.keras.utils.get_file(filename, url_test_data)\n",
        "  emnist_test_data = io.loadmat(path)\n",
        "  test_image = emnist_test_data['test_x']\n",
        "  test_label = emnist_test_data['test_y']\n",
        "  return test_image, test_label\n",
        "\n",
        "\n",
        "def make_federated_data_with_malicious(client_data,\n",
        "                                       dataset_malicious,\n",
        "                                       client_ids,\n",
        "                                       with_attack=1,attack_no=2):\n",
        "  \"\"\"Make federated dataset with potential attackers.\"\"\"\n",
        "  benign_dataset = [\n",
        "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
        "      for x in client_ids\n",
        "  ]\n",
        "  malicious_dataset = [dataset_malicious for x in client_ids]\n",
        "  if with_attack:\n",
        "    client_type_list = [tf.cast(0, tf.bool)] * (len(client_ids) - attack_no) + attack_no * [\n",
        "        tf.cast(1, tf.bool)\n",
        "    \n",
        "    ]\n",
        "  else:\n",
        "    client_type_list = [tf.cast(0, tf.bool)] * len(client_ids)\n",
        " \n",
        "  return benign_dataset, malicious_dataset, client_type_list\n",
        "\n",
        "\n",
        "def sample_clients_with_malicious(client_data,\n",
        "                                  client_ids,\n",
        "                                  dataset_malicious,\n",
        "                                  num_clients=3,\n",
        "                                  with_attack=1,attack_no=2):\n",
        "  \"\"\"Sample client and make federated dataset.\"\"\"\n",
        "  sampled_clients = np.random.choice(client_ids, num_clients)\n",
        "  federated_train_data, federated_malicious_data, client_type_list = make_federated_data_with_malicious(\n",
        "      client_data, dataset_malicious, sampled_clients, with_attack,attack_no)\n",
        "  return federated_train_data, federated_malicious_data, client_type_list\n",
        "\n",
        "\n",
        "def create_keras_model():\n",
        "  \"\"\"Build compiled keras model.\"\"\"\n",
        "  num_classes = 10 if True else 62\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(\n",
        "          32,\n",
        "          kernel_size=(3, 3),\n",
        "          activation='relu',\n",
        "          input_shape=data_shape,\n",
        "          data_format=data_format),\n",
        "      tf.keras.layers.Conv2D(\n",
        "          64, kernel_size=(3, 3), activation='relu', data_format=data_format),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2, 2), data_format=data_format),\n",
        "      tf.keras.layers.Dropout(0.25),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "emnist_train, _ = tff.simulation.datasets.emnist.load_data(\n",
        "      only_digits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image, test_label = load_test_data()"
      ],
      "metadata": {
        "id": "hNpjI-xU-m_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_malicious, target_x, target_y = load_malicious_dataset(30)\n",
        "len(dataset_malicious)\n",
        "\n",
        "\n",
        "  # prepare model_fn.\n",
        "example_dataset = preprocess(emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[0]))\n",
        "input_spec = example_dataset.element_spec\n",
        "\n",
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(keras_model,\n",
        "                                       input_spec=input_spec,\n",
        "                                       loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                                       metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "\n",
        "def server_optimizer_fn():\n",
        "    return tf.keras.optimizers.SGD(\n",
        "        learning_rate=1.,\n",
        "        momentum=0.,\n",
        "        nesterov=True)\n",
        "\n",
        "\n",
        "def evaluate(state, x, y, target_x, target_y, batch_size=100):\n",
        "  \"\"\"Evaluate the model on both main task and target task.\"\"\"\n",
        "  keras_model = create_keras_model()\n",
        "  keras_model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "  state.model.assign_weights_to(keras_model)\n",
        "  test_metrics = keras_model.evaluate(x, y, batch_size=batch_size)\n",
        "  test_metrics_target = keras_model.evaluate(\n",
        "      target_x, target_y, batch_size=batch_size)\n",
        "  return test_metrics, test_metrics_target\n",
        "\n",
        "\n",
        "\n",
        "client_update_function = ClientProjectBoost(\n",
        "      boost_factor=float(5),\n",
        "      norm_bound=3. is 3, # The maximum norm for malicious update before boosting\n",
        "      round_num=5)\n",
        "#client_update_function = ClientExplicitBoosting(boost_factor=float(5))\n",
        "\n",
        "# attack ---> The number of attack tasks we want to insert\n",
        "# Number of local rounds used to compute the malicious update\n",
        "\n",
        "query = tensorflow_privacy.GaussianSumQuery(0.7,0.0)#--- L2_Norm threshold\n",
        "query = tensorflow_privacy.NormalizedQuery(query, number_clients)\n",
        "dp_agg_factory = tff.aggregators.DifferentiallyPrivateFactory(query)\n",
        "\n",
        " # Clips records to bound the L2 norm, then adds Gaussian noise to the sum\n",
        " #The clipped l2 norm , The multiplication factor to ensure privacy\n",
        "\n",
        "\n",
        "iterative_process = build_federated_averaging_process_attacked(\n",
        "    model_fn=model_fn,\n",
        "    model_update_aggregation_factory=dp_agg_factory,\n",
        "    client_update_tf=client_update_function,\n",
        "    server_optimizer_fn=server_optimizer_fn)\n",
        "state = iterative_process.initialize()"
      ],
      "metadata": {
        "id": "h8_FBzac-tgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cur_round in range(1):\n",
        "    if cur_round % 1 == 1 // 2: #Attacking frequency of the attacker = 1\n",
        "      with_attack = 1\n",
        "      #write_print(file_handle, 'Attacker appears!')\n",
        "    else:\n",
        "      with_attack = 0\n",
        "    #print(with_attack)\n",
        "    # sample clients and make federated dataset\n",
        "    if (cur_round == 1):\n",
        "      federated_train_data, federated_malicious_data, client_type_list = sample_clients_with_malicious(\n",
        "          emnist_train,\n",
        "          client_ids=emnist_train.client_ids,\n",
        "          dataset_malicious=dataset_malicious,\n",
        "          num_clients=number_clients,\n",
        "          with_attack=with_attack,attack_no=0)\n",
        "    else:\n",
        "      federated_train_data, federated_malicious_data, client_type_list = sample_clients_with_malicious(\n",
        "          emnist_train,\n",
        "          client_ids=emnist_train.client_ids,\n",
        "          dataset_malicious=dataset_malicious,\n",
        "          num_clients=number_clients,\n",
        "          with_attack=with_attack,attack_no=0)\n",
        "\n",
        "    # one round of attacked federated averaging\n",
        "    #write_print(file_handle, 'Round starts!')\n",
        "    state, train_metrics,a= iterative_process.next(state, federated_train_data,\n",
        "                                                  federated_malicious_data,\n",
        "                                                  client_type_list)\n",
        "    data = np.array(a)\n",
        "    #data = np.array(t,dtype ='object')\n",
        "    \n",
        "    #tf.summary.histogram(\"%s-grad\" % g[1].name, g[0]) for g in grads\n",
        "   \n",
        "      #tf.summary.histogram(\"weights\",a)\n",
        "    \n",
        "    #np.save('weights'+ str(cur_round)+'.npy',data)\n",
        "    print(len(a))\n",
        "    \n",
        "    for j in range(len(a)):\n",
        "      f = plt.figure(figsize=(12,7))\n",
        "      plt.hist(a[j], density=True)\n",
        "      plt.show()\n",
        "    #print(t)"
      ],
      "metadata": {
        "id": "4yqQw2X0-6uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "oReIdcTZgfWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "VeB6WdSUgftk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if cur_round % 1 == 0:\n",
        "      test_metrics, test_metrics_target = evaluate(state, test_image,\n",
        "                                                   test_label, target_x,\n",
        "                                                   target_y)\n",
        "      print(test_metrics)\n",
        "      print(test_metrics_target)"
      ],
      "metadata": {
        "id": "sx7v2TlZ-90Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,4):\n",
        "  plt.subplot(2, 2, i+1)\n",
        "  plt.imshow(target_x[i].reshape((28, 28)))\n",
        "  print(target_y[i])\n"
      ],
      "metadata": {
        "id": "zniFSzsC_BcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "!rm -rf ./logs/ \n",
        "logdir = \"/tmp/logs/scalars/training/\"\n",
        "if os.path.exists(logdir):\n",
        "  shutil.rmtree(logdir)\n",
        "\n",
        "# Your code to create a summary writer:\n",
        "summary_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "state = iterative_process.initialize()"
      ],
      "metadata": {
        "id": "NMtrHY87CWTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with summary_writer.as_default():\n",
        "  for round_num in range(1, 1):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)\n",
        "    for name, value in metrics['train'].items():\n",
        "      tf.summary.scalar(name, value, step=round_num)"
      ],
      "metadata": {
        "id": "CDIIr35m6dF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /tmp/logs/scalars/"
      ],
      "metadata": {
        "id": "QgwBB4x16ip8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}